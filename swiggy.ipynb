{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/rajeshkumar/Desktop/Swiggy project/swiggy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Count duplicates\n",
    "print(\"Duplicate rows:\", df.duplicated().sum())\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def parse_rating_count(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    if isinstance(x, str):\n",
    "        x = x.strip()\n",
    "        if \"Too Few\" in x:        # Case: \"Too Few Ratings\"\n",
    "            return np.nan\n",
    "        if x.endswith(\"ratings\"): # Case: \"50+ ratings\"\n",
    "            num = x.split()[0].replace(\"+\", \"\")\n",
    "            return int(num) if num.isdigit() else np.nan\n",
    "        if x.isdigit():           # Case: \"200\"\n",
    "            return int(x)\n",
    "    return np.nan   # anything else becomes NaN\n",
    "\n",
    "df['rating_count'] = df['rating_count'].apply(parse_rating_count).astype(float)\n",
    "df['cost'] = df['cost'].str.replace(\"₹\", \"\").str.strip().astype(float)\n",
    "import numpy as np\n",
    "\n",
    "# Replace '--' with NaN and convert to float\n",
    "df['rating'] = df['rating'].replace('--', np.nan).astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cleaned_data.csv\", index=False)\n",
    "print(\"✅ Cleaned dataset saved as cleaned_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessing complete: encoded_data.csv + encoder.pkl saved (indices preserved)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MultiLabelBinarizer\n",
    "import pickle\n",
    "\n",
    "# ---- Load cleaned dataset ----\n",
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "# ---- 1. Split city into sub_city and main_city ----\n",
    "df[['sub_city', 'main_city']] = df['city'].str.split(\",\", n=1, expand=True)\n",
    "df['sub_city'] = df['sub_city'].str.strip()\n",
    "df['main_city'] = df['main_city'].fillna(df['sub_city']).str.strip()\n",
    "\n",
    "# ---- 2. Encode \"name\" using LabelEncoder ----\n",
    "name_encoder = LabelEncoder()\n",
    "df['name_encoded'] = name_encoder.fit_transform(df['name'])\n",
    "\n",
    "# ---- 3. Encode \"main_city\" using OneHotEncoder ----\n",
    "city_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "city_encoded = city_encoder.fit_transform(df[['main_city']])\n",
    "\n",
    "city_df = pd.DataFrame(\n",
    "    city_encoded,\n",
    "    index=df.index,  # ✅ preserve same index as cleaned_data\n",
    "    columns=city_encoder.get_feature_names_out(['main_city'])\n",
    ")\n",
    "\n",
    "# ---- 4. Encode \"cuisine\" (multi-label) ----\n",
    "df['cuisine'] = df['cuisine'].fillna(\"\").str.split(\",\")\n",
    "mlb = MultiLabelBinarizer()\n",
    "cuisine_encoded = mlb.fit_transform(df['cuisine'])\n",
    "\n",
    "cuisine_df = pd.DataFrame(\n",
    "    cuisine_encoded,\n",
    "    index=df.index,  # ✅ preserve same index as cleaned_data\n",
    "    columns=mlb.classes_\n",
    ")\n",
    "\n",
    "# ---- 5. Concatenate all features (indices aligned) ----\n",
    "numerical_cols = ['rating', 'rating_count', 'cost']\n",
    "final_df = pd.concat(\n",
    "    [df[numerical_cols], df[['name_encoded']], city_df, cuisine_df],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ✅ Ensure index matches cleaned_data before saving\n",
    "assert (final_df.index == df.index).all(), \"Index mismatch detected!\"\n",
    "\n",
    "# ---- 6. Save Encoders ----\n",
    "with open(\"encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"name_encoder\": name_encoder,\n",
    "        \"city_encoder\": city_encoder,\n",
    "        \"cuisine_encoder\": mlb\n",
    "    }, f)\n",
    "\n",
    "# ---- 7. Save Preprocessed Dataset ----\n",
    "final_df.to_csv(\"encoded_data.csv\", index=False)\n",
    "\n",
    "print(\"✅ Preprocessing complete: encoded_data.csv + encoder.pkl saved (indices preserved)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cleaned = pd.read_csv(\"cleaned_data.csv\")\n",
    "encoded = pd.read_csv(\"encoded_data.csv\")\n",
    "\n",
    "# Check if lengths match\n",
    "print(\"Same length?\", len(cleaned) == len(encoded))\n",
    "\n",
    "# Check if indices align\n",
    "print(\"Same indices?\", cleaned.index.equals(encoded.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def recommend_restaurant_cosine(restaurant_name, top_n=5):\n",
    "    matches = cleaned[cleaned['name'].str.lower() == restaurant_name.lower()]\n",
    "    if matches.empty:\n",
    "        return f\"❌ Restaurant '{restaurant_name}' not found!\"\n",
    "    \n",
    "    idx = matches.index[0]\n",
    "    \n",
    "    # Compare only with that restaurant (not whole n x n)\n",
    "    sim_scores = cosine_similarity(\n",
    "        [encoded.iloc[idx]],   # query vector\n",
    "        encoded\n",
    "    )[0]\n",
    "    \n",
    "    # Get top N\n",
    "    top_indices = np.argsort(sim_scores)[::-1][1:top_n+1]\n",
    "    \n",
    "    return cleaned.iloc[top_indices][['name','city','cuisine','rating','cost']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cleaned = pd.read_csv(\"cleaned_data.csv\")\n",
    "encoded = pd.read_csv(\"encoded_data.csv\")\n",
    "\n",
    "# Check if lengths match\n",
    "print(\"Same length?\", len(cleaned) == len(encoded))\n",
    "\n",
    "# Check if indices align\n",
    "print(\"Same indices?\", cleaned.index.equals(encoded.index))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
